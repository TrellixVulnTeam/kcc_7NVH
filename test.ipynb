{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class StyleTransfer(nn.Module):\n",
    "    def __init__(self, encoder, tst_decoder, d_hidden, style_ratio, device):\n",
    "        super(StyleTransfer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.tst_decoder = tst_decoder\n",
    "        self.style_ratio = style_ratio\n",
    "\n",
    "        # TODO Size ?\n",
    "        self.context2mu = nn.Linear(d_hidden, d_hidden)\n",
    "        self.context2logv = nn.Linear(d_hidden, d_hidden)\n",
    "\n",
    "    def reparameterization(self, hidden):\n",
    "        mu = self.context2mean(hidden)\n",
    "        log_v = self.context2logv(hidden)\n",
    "\n",
    "        std = torch.exp(0.5 * log_v)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + (eps * std)\n",
    "\n",
    "        return z, mu, log_v\n",
    "\n",
    "    def forward(self, tst_src, tst_trg, teacher_forcing_ratio=0.5):\n",
    "        tst_src = tst_src.transpose(0, 1)\n",
    "        tst_trg = tst_trg.transpose(0, 1)\n",
    "        embedded = self.src_embedding(tst_src)\n",
    "        encoder_out, hidden, cell = self.encoder(embedded)\n",
    "\n",
    "        style_index = int(len(hidden) * (1 - self.style_ratio))\n",
    "        context_c, context_a = hidden[:style_index], hidden[style_index:]\n",
    "\n",
    "        content_c, content_mu, content_logv = self.reparameterization(context_c)\n",
    "        style_a, style_mu, style_logv = self.reparameterization(context_a)\n",
    "\n",
    "        total_latent = torch.cat(content_c, style_a)\n",
    "\n",
    "        # TODO cat? add?\n",
    "        hidden = torch.add(hidden, total_latent)\n",
    "\n",
    "        trg_len = tst_trg.shape[0]  # length of word\n",
    "        batch_size = tst_trg.shape[1]  # batch size\n",
    "        trg_vocab_size = self.tst_decoder.d_model\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        input = tst_trg[0, :]\n",
    "\n",
    "        for i in range(1, trg_len):\n",
    "            output, hidden, cell = self.tst_decoder(input, hidden, cell)\n",
    "            outputs[i] = output\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = tst_trg[i] if teacher_force else top1\n",
    "\n",
    "        return outputs, total_latent, content_c, content_mu, content_logv, style_a, style_mu, style_logv\n",
    "\n",
    "\n",
    "class StylizedNMT(nn.Module):\n",
    "    def __init__(self, encoder, nmt_decoder, total_latent, device):\n",
    "        super(StylizedNMT, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.nmt_decoder = nmt_decoder\n",
    "        self.total_latent = total_latent\n",
    "\n",
    "    def forward(self, nmt_src, nmt_trg, teacher_forcing_ratio=0.5):\n",
    "        nmt_src = nmt_src.transpose(0, 1)\n",
    "        nmt_trg = nmt_trg.transpose(0, 1)\n",
    "        embedded = self.src_embedding(nmt_src)\n",
    "        encoder_out, hidden, cell = self.encoder(embedded)\n",
    "\n",
    "        hidden = torch.add(hidden, self.total_latent)\n",
    "\n",
    "        trg_len = nmt_trg.shape[0]  # length of word\n",
    "        batch_size = nmt_trg.shape[1]  # batch size\n",
    "        trg_vocab_size = self.tst_decoder.d_model\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        input = nmt_trg[0, :]\n",
    "\n",
    "        for i in range(1, trg_len):\n",
    "            output, hidden, cell = self.tst_decoder(input, hidden, cell)\n",
    "            outputs[i] = output\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = nmt_trg[i] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, d_embed, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_embedding = nn.Embedding(d_model, d_embed)\n",
    "        self.encoder = nn.LSTM(input_size=d_embed, hidden_size=d_hidden, dropout=dropout,\n",
    "                               num_layers=n_layers, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.src_embedding(src))\n",
    "        outputs, hidden, cell = self.encoder(embedded)\n",
    "\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class TSTDecoder(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, d_embed, n_layers, dropout):\n",
    "        super(TSTDecoder, self).__init__()\n",
    "        self.trg_embedding = nn.Embedding(d_model, d_embed)\n",
    "        self.tst_decoder = nn.LSTM(input_size=d_embed, hidden_size=d_hidden, dropout=dropout,\n",
    "                                   num_layers=n_layers, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(d_hidden, d_model)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.insqueeze(0)\n",
    "        embedded = self.dropout(self.trg_embedding(input))\n",
    "\n",
    "        outputs, hidden, cell = self.tst_decoder(embedded, hidden, cell)\n",
    "        tst_out = self.fc(outputs.squezze(0))\n",
    "\n",
    "        return tst_out, hidden, cell\n",
    "\n",
    "\n",
    "class NMTDecoder(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, d_embed, n_layers, dropout):\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        self.trg_embedding = nn.Embedding(d_model, d_embed)\n",
    "        self.nmt_decoder = nn.LSTM(input_size=d_embed, hidden_size=d_hidden, dropout=dropout,\n",
    "                                   num_layers=n_layers, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(d_hidden, d_model)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.insqueeze(0)\n",
    "        embedded = self.dropout(self.trg_embedding(input))\n",
    "\n",
    "        outputs, hidden, cell = self.nmt_decoder(embedded, hidden, cell)\n",
    "        nmt_out = self.fc(outputs.squezze(0))\n",
    "\n",
    "        return nmt_out, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['encoder.src_embedding.weight', 'encoder.encoder.weight_ih_l0', 'encoder.encoder.weight_hh_l0', 'encoder.encoder.bias_ih_l0', 'encoder.encoder.bias_hh_l0', 'encoder.encoder.weight_ih_l0_reverse', 'encoder.encoder.weight_hh_l0_reverse', 'encoder.encoder.bias_ih_l0_reverse', 'encoder.encoder.bias_hh_l0_reverse', 'encoder.encoder.weight_ih_l1', 'encoder.encoder.weight_hh_l1', 'encoder.encoder.bias_ih_l1', 'encoder.encoder.bias_hh_l1', 'encoder.encoder.weight_ih_l1_reverse', 'encoder.encoder.weight_hh_l1_reverse', 'encoder.encoder.bias_ih_l1_reverse', 'encoder.encoder.bias_hh_l1_reverse', 'nmt_decoder.trg_embedding.weight', 'nmt_decoder.nmt_decoder.weight_ih_l0', 'nmt_decoder.nmt_decoder.weight_hh_l0', 'nmt_decoder.nmt_decoder.bias_ih_l0', 'nmt_decoder.nmt_decoder.bias_hh_l0', 'nmt_decoder.nmt_decoder.weight_ih_l0_reverse', 'nmt_decoder.nmt_decoder.weight_hh_l0_reverse', 'nmt_decoder.nmt_decoder.bias_ih_l0_reverse', 'nmt_decoder.nmt_decoder.bias_hh_l0_reverse', 'nmt_decoder.nmt_decoder.weight_ih_l1', 'nmt_decoder.nmt_decoder.weight_hh_l1', 'nmt_decoder.nmt_decoder.bias_ih_l1', 'nmt_decoder.nmt_decoder.bias_hh_l1', 'nmt_decoder.nmt_decoder.weight_ih_l1_reverse', 'nmt_decoder.nmt_decoder.weight_hh_l1_reverse', 'nmt_decoder.nmt_decoder.bias_ih_l1_reverse', 'nmt_decoder.nmt_decoder.bias_hh_l1_reverse', 'nmt_decoder.fc.weight', 'nmt_decoder.fc.bias'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Initializing Device: {device}')\n",
    "\n",
    "total_latent = torch.rand(1024, 1, 1)\n",
    "encoder = Encoder(d_model=512, d_hidden=1024, d_embed=256, n_layers=2, dropout=0.1)\n",
    "nmt_decoder = NMTDecoder(d_model=512, d_hidden=1024, d_embed=256, n_layers=2, dropout=0.1)\n",
    "nmt_model = StylizedNMT(encoder, nmt_decoder, total_latent=total_latent, device=device)\n",
    "nmt_optimizer = torch.optim.AdamW(nmt_model.parameters(), lr=0.001)\n",
    "\n",
    "nmt_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of StylizedNMT(\n",
       "  (encoder): Encoder(\n",
       "    (src_embedding): Embedding(512, 256)\n",
       "    (encoder): LSTM(256, 1024, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (nmt_decoder): NMTDecoder(\n",
       "    (trg_embedding): Embedding(512, 256)\n",
       "    (nmt_decoder): LSTM(256, 1024, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in nmt_model.named_parameters():\n",
    "    if \"encoder\" in name:\n",
    "        param.required_grads = False\n",
    "nmt_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

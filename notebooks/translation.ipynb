{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699a2835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dill'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa12ae269b9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdill\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dill'"
     ]
    }
   ],
   "source": [
    "''' Translate input text with trained model. '''\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import dill as pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "from torchtext.data import Dataset\n",
    "from transformer.Models import Transformer\n",
    "from transformer.Translator import Translator\n",
    "\n",
    "\n",
    "def load_model(opt, device):\n",
    "\n",
    "    checkpoint = torch.load(opt.model, map_location=device)\n",
    "    model_opt = checkpoint['settings']\n",
    "\n",
    "    model = Transformer(\n",
    "        model_opt.src_vocab_size,\n",
    "        model_opt.trg_vocab_size,\n",
    "\n",
    "        model_opt.src_pad_idx,\n",
    "        model_opt.trg_pad_idx,\n",
    "\n",
    "        trg_emb_prj_weight_sharing=model_opt.proj_share_weight,\n",
    "        emb_src_trg_weight_sharing=model_opt.embs_share_weight,\n",
    "        d_k=model_opt.d_k,\n",
    "        d_v=model_opt.d_v,\n",
    "        d_model=model_opt.d_model,\n",
    "        d_word_vec=model_opt.d_word_vec,\n",
    "        d_inner=model_opt.d_inner_hid,\n",
    "        n_layers=model_opt.n_layers,\n",
    "        n_head=model_opt.n_head,\n",
    "        dropout=model_opt.dropout).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    print('[Info] Trained model state loaded.')\n",
    "    return model \n",
    "\n",
    "\n",
    "def main():\n",
    "    '''Main Function'''\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='translate.py')\n",
    "\n",
    "    parser.add_argument('-model', required=True,\n",
    "                        help='Path to model weight file')\n",
    "    parser.add_argument('-data_pkl', required=True,\n",
    "                        help='Pickle file with both instances and vocabulary.')\n",
    "    parser.add_argument('-output', default='/output/pred.txt',\n",
    "                        help=\"\"\"Path to output the predictions (each line will\n",
    "                        be the decoded sequence\"\"\")\n",
    "    parser.add_argument('-beam_size', type=int, default=5)\n",
    "    parser.add_argument('-max_seq_len', type=int, default=100)\n",
    "    parser.add_argument('-no_cuda', action='store_true')\n",
    "\n",
    "    # TODO: Translate bpe encoded files \n",
    "    #parser.add_argument('-src', required=True,\n",
    "    #                    help='Source sequence to decode (one line per sequence)')\n",
    "    #parser.add_argument('-vocab', required=True,\n",
    "    #                    help='Source sequence to decode (one line per sequence)')\n",
    "    # TODO: Batch translation\n",
    "    #parser.add_argument('-batch_size', type=int, default=30,\n",
    "    #                    help='Batch size')\n",
    "    #parser.add_argument('-n_best', type=int, default=1,\n",
    "    #                    help=\"\"\"If verbose is set, will output the n_best\n",
    "    #                    decoded sentences\"\"\")\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    opt.cuda = not opt.no_cuda\n",
    "\n",
    "    data = pickle.load(open(opt.data_pkl, 'rb'))\n",
    "    SRC, TRG = data['vocab']['src'], data['vocab']['trg']\n",
    "    opt.src_pad_idx = SRC.vocab.stoi[Constants.PAD_WORD]\n",
    "    opt.trg_pad_idx = TRG.vocab.stoi[Constants.PAD_WORD]\n",
    "    opt.trg_bos_idx = TRG.vocab.stoi[Constants.BOS_WORD]\n",
    "    opt.trg_eos_idx = TRG.vocab.stoi[Constants.EOS_WORD]\n",
    "\n",
    "    test_loader = Dataset(examples=data['test'], fields={'src': SRC, 'trg': TRG})\n",
    "    \n",
    "    device = torch.device('cuda' if opt.cuda else 'cpu')\n",
    "    translator = Translator(\n",
    "        model=load_model(opt, device),\n",
    "        beam_size=opt.beam_size,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        src_pad_idx=opt.src_pad_idx,\n",
    "        trg_pad_idx=opt.trg_pad_idx,\n",
    "        trg_bos_idx=opt.trg_bos_idx,\n",
    "        trg_eos_idx=opt.trg_eos_idx).to(device)\n",
    "\n",
    "    unk_idx = SRC.vocab.stoi[SRC.unk_token]\n",
    "    with open(opt.output, 'w') as f:\n",
    "        for example in tqdm(test_loader, mininterval=2, desc='  - (Test)', leave=False):\n",
    "            #print(' '.join(example.src))\n",
    "            src_seq = [SRC.vocab.stoi.get(word, unk_idx) for word in example.src]\n",
    "            pred_seq = translator.translate_sentence(torch.LongTensor([src_seq]).to(device))\n",
    "            pred_line = ' '.join(TRG.vocab.itos[idx] for idx in pred_seq)\n",
    "            pred_line = pred_line.replace(Constants.BOS_WORD, '').replace(Constants.EOS_WORD, '')\n",
    "            #print(pred_line)\n",
    "            f.write(pred_line.strip() + '\\n')\n",
    "\n",
    "    print('[Info] Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3bccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tokenizers\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(\"./data/GYAFC_Corpus/Family_Relationships/tune/*\")\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for fi in files:\n",
    "#     file = open(fi, \"r\", encoding=\"utf8\")\n",
    "#     for line in file.readlines():\n",
    "#         with open(f\"{fi}_fr_tune.txt\", \"a\", encoding=\"utf8\") as f:\n",
    "#             if line != \"\\n\":\n",
    "#                 f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_file = './data/processed/raw/fr_formal_train.txt'\n",
    "informal_file = './data/processed/raw/fr_informal_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51967, 1) (51967, 1)\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.DataFrame()\n",
    "formal_df = pd.read_fwf(formal_file, header=None)\n",
    "formal_df = formal_df.drop(1, axis=1)\n",
    "formal_df.columns = ['formal']\n",
    "informal_df = pd.read_fwf(informal_file, header=None)\n",
    "informal_df = informal_df.drop([1, 2, 3, 4, 5], axis=1)\n",
    "informal_df.columns = ['informal']\n",
    "\n",
    "print(formal_df.shape, informal_df.shape)\n",
    "total_df = pd.concat([formal_df, informal_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51967, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>informal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51962</th>\n",
       "      <td>Of course, it depends on what type of relation...</td>\n",
       "      <td>of corse it depends on what relation u r looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51963</th>\n",
       "      <td>Wear a sign that say \"Hi!\"</td>\n",
       "      <td>Wear a sign that says Hi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51964</th>\n",
       "      <td>I do not like when guys play games with me.</td>\n",
       "      <td>I don't believe in playing games, I hate when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51965</th>\n",
       "      <td>How old are you?</td>\n",
       "      <td>(or w/e)   p.s gurl how old r u ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51966</th>\n",
       "      <td>If you watch her, you might be able to learn w...</td>\n",
       "      <td>Try to watch her to see what kind of things sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  formal  \\\n",
       "51962  Of course, it depends on what type of relation...   \n",
       "51963                         Wear a sign that say \"Hi!\"   \n",
       "51964        I do not like when guys play games with me.   \n",
       "51965                                   How old are you?   \n",
       "51966  If you watch her, you might be able to learn w...   \n",
       "\n",
       "                                                informal  \n",
       "51962  of corse it depends on what relation u r looki...  \n",
       "51963                          Wear a sign that says Hi!  \n",
       "51964  I don't believe in playing games, I hate when ...  \n",
       "51965                  (or w/e)   p.s gurl how old r u ?  \n",
       "51966  Try to watch her to see what kind of things sh...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(total_df.shape)\n",
    "total_df.to_csv(\"./data/processed/raw/fr_train_pair.csv\", index=False)\n",
    "total_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 하이퍼파라미터 설정\n",
    "### 모델의 hyperparameter를 string으로 정의해 줍니다.\n",
    "- **character_coverage**: 얼마나 자소단위 셋을 줄여 단어단위 셋으로 coverage 시킬 것인지에 대한 모델 하이퍼파라미터\n",
    "- 실험적으로\n",
    "    + 중국어, 일본어 같이 자소단위로 이루어진 언어(rich character set)에서는 0.9995\n",
    "    + 다른언어(small character set)에 대해서 1로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--input=./data/processed/raw/em_formal_train.txt --pad_id=0 --pad_piece=[PAD] --bos_id=1 --bos_piece=[BOS] --eos_id=2 --eos_piece=[EOS] --unk_id=3 --unk_piece=[UNK] --user_defined_symbols=[SEP],[CLS],[MASK] --model_prefix=./data/tokenizer/formal_em_spm --vocab_size=2000 --max_sentence_length=9999 --character_coverage=1.0 --model_type=unigram'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = '--input={} \\\n",
    "--pad_id={} --pad_piece={} \\\n",
    "--bos_id={} --bos_piece={} \\\n",
    "--eos_id={} --eos_piece={} \\\n",
    "--unk_id={} --unk_piece={} \\\n",
    "--user_defined_symbols={} \\\n",
    "--model_prefix={} \\\n",
    "--vocab_size={} \\\n",
    "--max_sentence_length={} \\\n",
    "--character_coverage={} \\\n",
    "--model_type={}'\n",
    "\n",
    "train_input_file = \"./data/processed/raw/em_formal_train.txt\"\n",
    "pad_id = 0\n",
    "pad_piece = \"[PAD]\"\n",
    "bos_id = 1\n",
    "bos_piece = \"[BOS]\"\n",
    "eos_id = 2\n",
    "eos_piece = \"[EOS]\"\n",
    "unk_id = 3\n",
    "unk_piece = \"[UNK]\"\n",
    "user_defined_symbols = \"[SEP],[CLS],[MASK]\"\n",
    "prefix = './data/tokenizer/em_formal_spm'\n",
    "vocab_size = 2000\n",
    "max_sentence_length = 9999\n",
    "character_coverage = 1.0 # default \n",
    "model_type = 'unigram' # default: unigram\n",
    "\n",
    "\n",
    "cmd = parameter.format(train_input_file, \n",
    "                       pad_id, pad_piece,\n",
    "                       bos_id, bos_piece, \n",
    "                       eos_id, eos_piece, \n",
    "                       unk_id, unk_piece,\n",
    "                       user_defined_symbols,\n",
    "                       prefix,\n",
    "                       vocab_size,\n",
    "                       max_sentence_length,\n",
    "                       character_coverage,\n",
    "                       model_type)\n",
    "\n",
    "cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer 학습\n",
    "- 학습이 잘 완료되면 True라는 인자를 반환합니다.\n",
    "- 이부분이 완료되면, prefix를 가진 아래의 두개의 파일이 생성됩니다.\n",
    "    + model:실제로 사용되는 tokenizer 모델\n",
    "    + vocab: 참조하는 단어집합\n",
    "\n",
    "├── {prefix}.model  \n",
    "├── {prefix}.vocab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장에 Tokenizer 적용\n",
    "- 이제 실제 문장에 적용하기 위해서 sp모듈 새로 정의해, 이전에 학습한 {prefix}.model을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(f\"{prefix}.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### {prefix}.vocab 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{prefix}.vocab', encoding='utf-8') as f:\n",
    "    Vo = [doc.strip().split(\"\\t\") for doc in f]\n",
    "\n",
    "# w[0]: token name    \n",
    "# w[1]: token score\n",
    "word2idx = {w[0]: i for i, w in enumerate(Vo)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word2idx"
   ]
  },
  {
   "attachments": {
    "image-4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-4.png](attachment:image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize하기 전에 데이터 자체에 **\\<s>, \\</s>**를 넣어줘도 되지만, 패키지 자체에서 알아서 해주는 옵션(sp.SetEncodeExtraOptions)이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.SetEncodeExtraOptions('bos:eos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer 수행\n",
    "- EncodeAsPieces: string으로 tokenize\n",
    "- EncodeAsIds: ids으로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS]',\n",
       " '▁This',\n",
       " '▁e',\n",
       " 'B',\n",
       " 'ook',\n",
       " '▁is',\n",
       " '▁for',\n",
       " '▁the',\n",
       " '▁use',\n",
       " '▁of',\n",
       " '▁anyone',\n",
       " '▁any',\n",
       " 'where',\n",
       " '▁at',\n",
       " '▁no',\n",
       " '▁cost',\n",
       " '[EOS]']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = sp.EncodeAsPieces('This eBook is for the use of anyone anywhere at no cost')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 234, 212, 284, 722, 9, 35, 8, 317, 19, 634, 178, 917, 90, 126, 1276, 2]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokensIds = sp.EncodeAsIds('This eBook is for the use of anyone anywhere at no cost')\n",
    "tokensIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode Token \n",
    "- 위에서 쪼개진 token들을 그냥 공백기준으로 붙이면 _와 띄어쓰기 모호함에 따라 어색함이 생길 수 있습니다.\n",
    "- sp내의 Decode함수를 사용하면 쉽게 원복할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This eBook is for the use of anyone anywhere at no cost'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This eBook is for the use of anyone anywhere at no cost'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds(tokensIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sp\n",
    "dt = ['There are not cursed movies or weird things!', 'Do you want to learn the lyrics or actually meet them?', 'I am not sure yet.', 'That is how good it is.', 'Who cares about the Top 20 Celebrity Moments on Vh1?', 'I also like the show Friends.  Pheobe and Joey make it a very funny show.', 'The girls stopped gossiping about it so they no longer make it.', 'I would go to jail if I did it.', 'Ciara and Bow Wow', 'I do not believe he can cure anything, however.', 'You have exposed me which I thought would never happen. Why did you do this?', 'Veronica. Not only do I love brunettes, but she is from an extremely wealthy family.', 'You could learn more information with a Yahoo search.', 'The two sites are: Limewire (www.limewire.com), and Kazaa (www.kazaa.com).', 'Dogs enjoy lunch. Men enjoy pleasing woman.', 'The two least popular were Bye Kelly and Paris.', 'I would have to choose Pink Floyd.', 'What in the world, there is only one Titanic so why make a second movie?', 'I think you are talking about Perth in Western Australia.', 'You are a good songwriter.', 'If you have not had the opportunity to read the books, they are great and accessible for anybody interested.', 'Scary Movies one, two, three, and (as of April 4th) four.', 'The soviet dog, \"Layka\", was the first dog to go to space.', 'And what does their team actually do?', \"Oh course he is, don't pay Jennisfer any mind, she has no fun.\", 'Many different kinds of people like cartoons and draw them, not just stereotypical geeks. Everyone is different.', 'I had intimacy with an animal once.', 'I would say yes because I am somewhat certain that it is the same person.', 'I love that song as well, therefore I acquired their greatest hits compact disc.', 'I find I am beginning to like Nathan.', 'A woodchuck cannot chuck or eat wood.', 'He became a full demon in the second film, but she kissed him. The kiss made him revert back to normal.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 170, 12, 155, 10, 857, 8, 464, 68, 840, 1363, 98, 30, 2]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.EncodeAsIds(dt[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, vocab: vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.vocab.EncodeAsIds(self.data[idx].strip())\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for x in self.data:\n",
    "            yield x\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.vocab.DecodeIds(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52595 52595\n"
     ]
    }
   ],
   "source": [
    "formal_data = total_df[\"formal\"].tolist()\n",
    "informal_data = total_df[\"informal\"].tolist()\n",
    "print(len(formal_data), len(informal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(formal_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Garbage Man, Geraldine McEwan is Miss Scattergoods, Christopher Nee', 'After one year it is converted to a movie.  It is 45 years old, and started with the writer in mind.', 'It is simply demonstrating that adults investigate things excessively.', \"Get your own so you don't have to waste your time watching this!\", 'Unexpectedly, I have a shitload.', 'Working for others is not what I want to do.', 'I do not believe she is involved with it in any way.', 'These are not websites, they are programs on which you can share mp3s, etc.: limewire, eMule, and ares.', 'Bob wrote most of his song on this piano.', 'I dislike christian influence music. You should try out bands like Kittie, Helalyn Flowers, and Arch Enemy.', 'He cannot. He is too busy playing basketball.', 'A shipment of breast implants arrived at his house.', 'Ruining endings, and being critical reduces the fun of situations.', 'He did not, he simply took some time off work to help Hallie and improve his lifestyle.', 'I have tried getting free I-pod music without any luck.', \"It doesn't matter what it means. Invariantology is an unusual word.\", 'I have obviously allowed others to intuit my actual age.', 'It is usually shown on the weekends', 'Half.com has many great movies, etc. For cheap!', 'I believe your mother is so rotund that if she procured a shoe shine, she would be unable to see her shoes and would therefore', 'You are twenty-one and still believe in horoscopes?  Only you can make or destroy your future.', 'We should start a letter-writing campaign to such a television.', 'Personally I think it is one of the worst movies I have seen.', 'Thanks for putting the \"la la la la la\" part in there.', \"It's Mrs. Anubis.\", 'Yes. It was called The Maxx.', 'I think Kelly Clarkson is part of that band.', 'Although this attractive singer is Arabian, his lyrics are written in English.', \"No, usually I don't. When there are only a few answers, I can't stop myself.\", \"Have you seen the UK 'Pimp my Ride'?\", 'While not immediately, perhaps in a small number of months to a year in time.', \"I'm not sure that I agree, but my friend does.\"]\n",
      "32\n",
      "After one year it is converted to a movie.  It is 45 years old, and started with the writer in mind.\n"
     ]
    }
   ],
   "source": [
    "for batch, data in enumerate(dataloader):\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(data.__getitem__(1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __init__(self, data, voacb: spm.SentencePieceProcessor, sep_id: str=\"[SEP]\", cls_id: str=\"[CLS]\",\n",
    "#                  mask_id: str=\"[MASK]\", pad_id: str=\"[PAD]\", seq_len: int=512, mask_frac: float=0.15, p: float=0.5):\n",
    "#         super(CustomDataset, self).__init__()\n",
    "#         self.voacb = vocab\n",
    "#         self.data = data\n",
    "#         self.seq_len = seq_len\n",
    "#         self.sep_id = vocab.piece_to_id(sep_id)\n",
    "#         self.cls_id = vocab.piece_to_id(cls_id)\n",
    "#         self.mask_id = voacb.piece_to_id(mask_id)\n",
    "#         self.pad_id = vocab.piece_to_id(pad_id)\n",
    "#         self.p = p\n",
    "#         self.mask_frac = mask_frac\n",
    "\n",
    "\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         seq1 = self.vocab.EncodeAsIds(self.data[i].strip())\n",
    "#         seq2_idx = i+1\n",
    "#         # decide wheter use random next sentence or not for NSP task\n",
    "#         if random.random() > p:\n",
    "#             is_next = torch.tensor(1)\n",
    "#             while seq2_idx == i+1:\n",
    "#                 seq2_idx = random.randint(0, len(data))\n",
    "#         else:\n",
    "#             is_next = torch.tensor(0)\n",
    "\n",
    "#         seq2 = self.vocab.EncodeAsIds(self.data[seq2_idx])\n",
    "\n",
    "#         if len(seq1) + len(seq2) >= self.seq_len - 3: # except 1 [CLS] and 2 [SEP]\n",
    "#             idx = self.seq_len - 3 - len(seq1)\n",
    "#             seq2 = seq2[:idx]\n",
    "\n",
    "#         # sentence embedding: 0 for A, 1 for B\n",
    "#         mlm_target = torch.tensor([self.cls_id] + seq1 + [self.sep_id] + seq2 + [self.sep_id] + [self.pad_id] * (self.seq_len - 3 - len(seq1) - len(seq2))).long().contiguous()\n",
    "#         sent_emb = torch.ones((mlm_target.size(0)))\n",
    "#         _idx = len(seq1) + 2\n",
    "#         sent_emb[:_idx] = 0\n",
    "        \n",
    "#         def masking(data):\n",
    "#             data = torch.tensor(data).long().contiguous()\n",
    "#             data_len = data.size(0)\n",
    "#             ones_num = int(data_len * self.mask_frac)\n",
    "#             zeros_num = data_len - ones_num\n",
    "#             lm_mask = torch.cat([torch.zeros(zeros_num), torch.ones(ones_num)])\n",
    "#             lm_mask = lm_mask[torch.randperm(data_len)]\n",
    "#             data = data.masked_fill(lm_mask.bool(), self.mask_id)\n",
    "\n",
    "#             return data\n",
    "\n",
    "#         mlm_train = torch.cat([torch.tensor([self.cls_id]), masking(seq1), torch.tensor([self.sep_id]), masking(seq1), torch.tensor([self.sep_id])]).long().contiguous()\n",
    "#         mlm_train = torch.cat([mlm_train, torch.tensor([self.pad_id] * (512 - mlm_train.size(0)))]).long().contiguous()\n",
    "\n",
    "#         # mlm_train, mlm_target, sentence embedding, NSP target\n",
    "#         return mlm_train, mlm_target, sent_emb, is_next\n",
    "#         # return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tokenizers\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(\"./data/tokenizer/train_em_formal_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = [[47, 84, 636], [372, 345, 874]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.DecodeIds(i) for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.752358913421631, 8.410636901855469], [3.7723755836486816, 3.640380382537842]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4.7524, 8.4106],\n",
       "        [3.7724, 3.6404]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.rand(2, 2)*10)\n",
    "print(a.tolist())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5248565673828125,\n",
       "  0.8026675581932068,\n",
       "  0.04119044542312622,\n",
       "  0.3099430203437805,\n",
       "  0.7548211216926575,\n",
       "  0.49521517753601074,\n",
       "  0.5619834661483765,\n",
       "  0.5527728796005249,\n",
       "  0.9217063188552856],\n",
       " [0.13436448574066162,\n",
       "  0.7198908925056458,\n",
       "  0.32315880060195923,\n",
       "  0.49836790561676025,\n",
       "  0.9914924502372742,\n",
       "  0.2773929238319397,\n",
       "  0.4438886046409607,\n",
       "  0.8123650550842285,\n",
       "  0.48424428701400757]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(2, 10)\n",
    "b[:, 1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = [(\"a,\", \"b\")]\n",
    "for i, j in c:\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7, 3]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b =torch.argmax(b, dim=1).tolist()\n",
    "print(b)\n",
    "c.append(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. ⁇ ']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.DecodeIds(i) for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.rand(3)\n",
    "d = torch.rand(3)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3908649682998657, 0.9498142600059509, 0.8346061706542969], [0.6791485548019409, 0.5381976366043091, 0.7374628782272339]]\n"
     ]
    }
   ],
   "source": [
    "e = c.tolist()\n",
    "f = d.tolist()\n",
    "x = []\n",
    "x.append(e)\n",
    "x.append(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3908649682998657, 0.6791485548019409],\n",
       " [0.9498142600059509, 0.5381976366043091],\n",
       " [0.8346061706542969, 0.7374628782272339]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(list, zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 48])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand([4, 10, 24])\n",
    "b = torch.rand([4, 10, 24])\n",
    "c = torch.cat((a, b), -1)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
